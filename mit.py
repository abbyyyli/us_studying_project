import requests
from bs4 import BeautifulSoup
import json

# MIT ç¶²é 
url = "https://www.mit.edu/about"
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.0.0 Safari/537.36"
}

# ç™¼é€ GET è«‹æ±‚
response = requests.get(url, headers=headers)
soup = BeautifulSoup(response.text, "html.parser")

# 1ï¸âƒ£ æå–ä¸»è¦å…§å®¹æ®µè½ï¼ˆæ‰¾æ‰€æœ‰ <p>ï¼‰
paragraphs = soup.find_all("p")

# 2ï¸âƒ£ éæ¿¾å…§å®¹ä¸¦è™•ç†è¶…é€£çµ
content = []
for p in paragraphs:
    text_parts = []
    for element in p.contents:
        if element.name == "a":
            text_parts.append(f"{element.get_text(strip=True)} ({element['href']})")  # è™•ç†è¶…é€£çµ
        elif isinstance(element, str):  # ç¢ºä¿æ˜¯å­—ä¸²
            text_parts.append(element.strip())

    full_text = " ".join(text_parts).strip()
    if full_text:  # é¿å…åŠ å…¥ç©ºè¡Œ
        content.append(full_text)

# 3ï¸âƒ£ è¼¸å‡º MIT å…§å®¹
print("\nğŸ” MIT é é¢å…§å®¹ï¼š")
for text in content:
    print(text)

# 4ï¸âƒ£ å­˜æˆ JSON æª”æ¡ˆ
mit_content = {"content": content}

with open("mit_about_content.json", "w", encoding="utf-8") as json_file:
    json.dump(mit_content, json_file, ensure_ascii=False, indent=4)

# 5ï¸âƒ£ å­˜æˆ TXT æª”æ¡ˆ
with open("mit_about_content.txt", "w", encoding="utf-8") as txt_file:
    txt_file.write("\n".join(content))

print("âœ… MIT å…§å®¹å·²æˆåŠŸæå–ä¸¦å­˜å…¥ mit_about_content.json å’Œ mit_about_content.txtï¼")
