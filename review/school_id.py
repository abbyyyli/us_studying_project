import requests
import json
import time
import random

# ğŸ”— Niche API URL
search_url = "https://www.niche.com/api/entity-reviews/"

# ğŸ“ List of schools
school_names = [
    "Massachusetts Institute of Technology", "Yale University", "Stanford University",
    "Columbia University", "Brown University", "Duke University", "Washington University in St. Louis",
    "Georgetown University", "University of Florida", "University of Notre Dame", "Princeton University",
    "Harvard University", "Dartmouth College", "Rice University", "Boston University",
    "University of Pennsylvania", "Vanderbilt University", "Carnegie Mellon University",
    "California Institute of Technology", "Tulane University", "University of Chicago",
    "University of California - Berkeley", "University of Southern California",
    "University of North Carolina at Chapel Hill", "Washington and Lee University",
    "Harvey Mudd College", "Wellesley College", "Northwestern University",
    "University of Michigan - Ann Arbor", "Johns Hopkins University", "Cornell University",
    "University of California - Los Angeles", "Claremont McKenna College", "New York University",
    "University of Virginia", "Emory University", "Georgia Institute of Technology",
    "Amherst College", "Grinnell College", "Wake Forest University", "Middlebury College",
    "Bowdoin College", "University of Illinois Urbana-Champaign", "Texas A&M University",
    "University of Texas - Austin", "University of Georgia", "New Mexico Tech",
    "Virginia Tech", "Florida State University", "University of Miami", "Michigan State University",
    "Barnard College", "Boston College", "Swarthmore College", "Williams College",
    "Pomona College", "Davidson College", "Tufts University", "Northeastern University",
]

# ğŸ›  Multiple User-Agents (to avoid detection)
user_agents = [
    
    "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Mobile Safari/537.36",
]

# ğŸ« Dictionary to store school IDs
school_ids = {}

# ğŸ”„ Start requests
for school in school_names:
    params = {"query": school, "context": "college", "page": 1, "limit": 1}
    headers = {"User-Agent": random.choice(user_agents)}
    
    retries = 3  # Maximum retries
    while retries > 0:
        response = requests.get(search_url, params=params, headers=headers)

        if response.status_code == 200:
            results = response.json()
            if "items" in results and results["items"]:
                school_id = results["items"][0]["entity"]["uuid"]
                school_ids[school] = school_id
                print(f"âœ… {school} çš„ School IDï¼š{school_id}")
            else:
                print(f"âŒ æœªæ‰¾åˆ° {school} çš„ ID")
            break  # Exit retry loop

        elif response.status_code == 403:
            print(f"ğŸš« 403 Forbidden - {school} è¢«å°é–ï¼Œç­‰å¾… 30 ç§’å¾Œé‡è©¦...")
            time.sleep(30)  # Wait before retrying
            retries -= 1

        elif response.status_code == 404:
            print(f"âŒ 404 Not Found - {school} çš„ ID ç„¡æ³•æ‰¾åˆ°")
            break  # No need to retry

        else:
            print(f"âŒ {school} è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")
            retries -= 1
            time.sleep(5)  # Short delay before retry

    time.sleep(random.uniform(5, 15))  # Add random delay

# ğŸ“ Save results
with open("school_ids.json", "w", encoding="utf-8") as f:
    json.dump(school_ids, f, indent=4)

print("ğŸ‰ æ‰€æœ‰å­¸æ ¡ ID å·²ç²å–ä¸¦å­˜å…¥ school_ids.json")
